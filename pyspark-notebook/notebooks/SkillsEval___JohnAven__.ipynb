{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PySpark Evaluation\n",
    "\n",
    "Date:  06_29_18\n",
    "\n",
    "Candidate: John A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in with command to read parquet file into a dataframe\n",
    "parqFileName = 's3://caserta-bucket1/train.pqt'\n",
    "\n",
    "df = spark.read.parquet(parqFileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the total count of crimes that happened on a Tuesday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of crimes commited on a Tuesday: 124965\n"
     ]
    }
   ],
   "source": [
    "total_number_of_crimes_on_Tuesday = df.where(df.DayOfWeek=='Tuesday').count()\n",
    "print 'Total number of crimes commited on a Tuesday: {0}'.format(total_number_of_crimes_on_Tuesday)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which Police District has the most crime?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "District with the most crime is: SOUTHERN\n"
     ]
    }
   ],
   "source": [
    "# import the spark-sql functions library\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "# aggregate the column by district and then get the count of crimes which happenin that district. Name the column\n",
    "# of crime counts as Total_Number_of_Crimes\n",
    "total_crime_by_district_df = df.groupBy(['PdDistrict']).agg(F.count('PdDistrict').alias('Total_Number_of_Crimes'))\n",
    "\n",
    "# We could sort descending and take the first column, but instead we use the desc function for ordering and take \n",
    "# only the first Row RDD (list returned - so have to take the 0th entry) and then since the name of the district\n",
    "# is in the first column we take the first entry.\n",
    "district_with_the_most_crime = total_crime_by_district_df.orderBy(F.desc('Total_Number_of_Crimes')).take(1)[0][0]\n",
    "\n",
    "print 'District with the most crime is: {0}'.format(district_with_the_most_crime)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the maximum length of each string column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+--------------+---------------+---------------+------------+\n",
      "|max(Category)|max(Descript)|max(DayOfWeek)|max(PdDistrict)|max(Resolution)|max(Address)|\n",
      "+-------------+-------------+--------------+---------------+---------------+------------+\n",
      "|           27|           73|             9|             10|             38|          44|\n",
      "+-------------+-------------+--------------+---------------+---------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the list of columns to apply transforms on\n",
    "string_columns =  [item[0] for item in df.dtypes if item[1] == 'string']\n",
    "\n",
    "# define a UDF to compute the length of the strings in the  column\n",
    "from pyspark.sql.types import IntegerType\n",
    "string_length_udf = F.udf(lambda x: len(x),IntegerType())\n",
    "\n",
    "# Apply the UDF to the \n",
    "df_of_string_lengths = df.select([string_length_udf(name).alias(name) for name in string_columns])\n",
    "\n",
    "# Create the aggregation expressions\n",
    "aggregation_expressions = [F.max(col) for col in string_columns]\n",
    "\n",
    "# Apply the aggregation expressions\n",
    "df_of_string_lengths.agg(*aggregation_expressions).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the min, max, and average of each column that is a number of any type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+-------------------+--------+------+-----------------+\n",
      "|    min(X)|max(X)|             avg(X)|  min(Y)|max(Y)|           avg(Y)|\n",
      "+----------+------+-------------------+--------+------+-----------------+\n",
      "|-122.51364|-120.5|-122.42261639461971|37.70788|  90.0|37.77102031342325|\n",
      "+----------+------+-------------------+--------+------+-----------------+\n",
      "\n",
      "+-------+--------------------+-------------------+\n",
      "|summary|                   X|                  Y|\n",
      "+-------+--------------------+-------------------+\n",
      "|  count|              878049|             878049|\n",
      "|   mean| -122.42261639461971|  37.77102031342325|\n",
      "| stddev|0.030353645185028408|0.45689310592877364|\n",
      "|    min|          -122.51364|           37.70788|\n",
      "|    max|              -120.5|               90.0|\n",
      "+-------+--------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get list of columns with a 'numeric' type\n",
    "numeric_columns = [item[0] for item in df.dtypes if item[1] in ['int','float','double','long','short','decimal']]\n",
    "\n",
    "# Create the aggregation expressions. Make sure in the product to have the functions as the second part of the \n",
    "# cartestion product to gaurantee that results for each column are grouped together.\n",
    "import itertools\n",
    "aggregation_expressions = [transform(col) for col,transform in itertools.product(numeric_columns,[F.min,F.max,F.avg])]\n",
    "\n",
    "#create a datagrame with just the numeric columns\n",
    "df_numeric = df.select(numeric_columns)\n",
    "\n",
    "# Compute the aggregations\n",
    "df_numeric.agg(*aggregation_expressions).show()\n",
    "\n",
    "# Another approach would be to generate the standard descriptive statistics as below.\n",
    "df_numeric.describe().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new dataframe with a new integer column called \"addr_words\" to have the number of words contained in the Address column.  Display the first 5 rows of Address and addr_words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|             Address|addr_words|\n",
      "+--------------------+----------+\n",
      "|  OAK ST / LAGUNA ST|         5|\n",
      "|  OAK ST / LAGUNA ST|         5|\n",
      "|VANNESS AV / GREE...|         5|\n",
      "|1500 Block of LOM...|         5|\n",
      "|100 Block of BROD...|         5|\n",
      "+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df = df.select(['Address'])\n",
    "\n",
    "# Version 1:\n",
    "# I will take the conventional definition that a word is any series of characters separated by a space\n",
    "def word_count(sentence):\n",
    "    if ' ' in sentence:\n",
    "        return len(sentence.split(' '))\n",
    "    else:\n",
    "        return 1\n",
    "from pyspark.sql.types import StringType\n",
    "word_count_udf = F.udf(lambda x: word_count(x),IntegerType())\n",
    "new_df = new_df.withColumn('addr_words',word_count_udf(new_df.Address))\n",
    "new_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the maximum and minimum number of words in the Address column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+\n",
      "|min_words|max_words|\n",
      "+---------+---------+\n",
      "|        3|       10|\n",
      "+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df.agg(*[F.min(new_df.addr_words).alias('min_words'), F.max(new_df.addr_words).alias('max_words')]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename the column \"PdDistrict\" to \"PoliceDistrict\" and print the schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Dates: timestamp (nullable = true)\n",
      " |-- Category: string (nullable = true)\n",
      " |-- Descript: string (nullable = true)\n",
      " |-- DayOfWeek: string (nullable = true)\n",
      " |-- PoliceDistrict: string (nullable = true)\n",
      " |-- Resolution: string (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- X: float (nullable = true)\n",
      " |-- Y: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumnRenamed('PdDistrict','PoliceDistrict')\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consider the following code snippet ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "gameFileLoc = \"s3://caserta-bucket1/Seahawks/game.csv\"\n",
    "\n",
    "gameDF = spark.read.format(\"org.apache.spark.sql.execution.datasources.csv.CSVFileFormat\") \\\n",
    "            .option(\"path\",gameFileLoc) \\\n",
    "            .option(\"sep\",\"\\t\") \\\n",
    "            .option(\"header\",\"true\") \\\n",
    "            .option(\"inferSchema\",\"true\") \\\n",
    "            .option(\"mode\", \"FAILFAST\") \\\n",
    "            .load(gameFileLoc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There is a problem with a column in the resulting dataframe.  Determine what the problem is and resolve the issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A preliminary inspection of the summary statistics show that Down has a value of 0. This isn't reasonable. I would not suggest changing this without discussing further with an SME."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|           GameKey|\n",
      "+-------+------------------+\n",
      "|  count|              2689|\n",
      "|   mean| 55805.21680922276|\n",
      "| stddev|184.99592840621645|\n",
      "|    min|             55530|\n",
      "|    max|             56157|\n",
      "+-------+------------------+\n",
      "\n",
      "+-------+------------------+\n",
      "|summary|            PlayID|\n",
      "+-------+------------------+\n",
      "|  count|              2689|\n",
      "|   mean|1997.0476013387877|\n",
      "| stddev|1164.1755589722163|\n",
      "|    min|                35|\n",
      "|    max|              4447|\n",
      "+-------+------------------+\n",
      "\n",
      "+-------+------------+\n",
      "|summary|HomeClubCode|\n",
      "+-------+------------+\n",
      "|  count|        2689|\n",
      "|   mean|        null|\n",
      "| stddev|        null|\n",
      "|    min|         SEA|\n",
      "|    max|         SEA|\n",
      "+-------+------------+\n",
      "\n",
      "+-------+---------------+\n",
      "|summary|VisitorClubCode|\n",
      "+-------+---------------+\n",
      "|  count|           2689|\n",
      "|   mean|           null|\n",
      "| stddev|           null|\n",
      "|    min|            ARZ|\n",
      "|    max|            TEN|\n",
      "+-------+---------------+\n",
      "\n",
      "+-------+----------+\n",
      "|summary|  GameDate|\n",
      "+-------+----------+\n",
      "|  count|      2689|\n",
      "|   mean|      null|\n",
      "| stddev|      null|\n",
      "|    min|10/13/2013|\n",
      "|    max| 9/24/2012|\n",
      "+-------+----------+\n",
      "\n",
      "+-------+------------------+\n",
      "|summary|UniversalTimeClock|\n",
      "+-------+------------------+\n",
      "|  count|              2669|\n",
      "|   mean|              null|\n",
      "| stddev|              null|\n",
      "|    min|           0:00:11|\n",
      "|    max|           5:22:10|\n",
      "+-------+------------------+\n",
      "\n",
      "+-------+---------+\n",
      "|summary|ClockTime|\n",
      "+-------+---------+\n",
      "|  count|     2689|\n",
      "|   mean|     null|\n",
      "| stddev|     null|\n",
      "|    min|     0:00|\n",
      "|    max|     9:59|\n",
      "+-------+---------+\n",
      "\n",
      "+-------+------------------+\n",
      "|summary|              Down|\n",
      "+-------+------------------+\n",
      "|  count|              2689|\n",
      "|   mean|1.8270732614354779|\n",
      "| stddev|1.1194620749559565|\n",
      "|    min|                 0|\n",
      "|    max|                 4|\n",
      "+-------+------------------+\n",
      "\n",
      "+-------+-----------------+\n",
      "|summary|        YardsToGo|\n",
      "+-------+-----------------+\n",
      "|  count|             2689|\n",
      "|   mean|7.864261807363332|\n",
      "| stddev|4.770688637323604|\n",
      "|    min|                0|\n",
      "|    max|               37|\n",
      "+-------+-----------------+\n",
      "\n",
      "+-------+--------+\n",
      "|summary|YardLine|\n",
      "+-------+--------+\n",
      "|  count|    2689|\n",
      "|   mean|    null|\n",
      "| stddev|    null|\n",
      "|    min|  ARZ 10|\n",
      "|    max|   TEN 8|\n",
      "+-------+--------+\n",
      "\n",
      "+-------+------------------+\n",
      "|summary|  AbsoluteYardLine|\n",
      "+-------+------------------+\n",
      "|  count|              2689|\n",
      "|   mean| 51.81703235403496|\n",
      "| stddev|25.481187475236226|\n",
      "|    min|                 1|\n",
      "|    max|                99|\n",
      "+-------+------------------+\n",
      "\n",
      "+-------+-------------------+\n",
      "|summary|   SpecialTeamsPlay|\n",
      "+-------+-------------------+\n",
      "|  count|               2689|\n",
      "|   mean| 0.1718110821866865|\n",
      "| stddev|0.37728632396253503|\n",
      "|    min|                  0|\n",
      "|    max|                  1|\n",
      "+-------+-------------------+\n",
      "\n",
      "+-------+------------------+\n",
      "|summary|           Quarter|\n",
      "+-------+------------------+\n",
      "|  count|              2689|\n",
      "|   mean|2.5050204537002605|\n",
      "| stddev|1.1266823109090776|\n",
      "|    min|                 1|\n",
      "|    max|                 5|\n",
      "+-------+------------------+\n",
      "\n",
      "+-------+------------------+\n",
      "|summary|          Sequence|\n",
      "+-------+------------------+\n",
      "|  count|              2689|\n",
      "|   mean|1997.0476013387877|\n",
      "| stddev|1164.1755589722163|\n",
      "|    min|                35|\n",
      "|    max|              4447|\n",
      "+-------+------------------+\n",
      "\n",
      "+-------+-------------------+\n",
      "|summary|      IsScoringPlay|\n",
      "+-------+-------------------+\n",
      "|  count|               2689|\n",
      "|   mean| 0.0766084046113797|\n",
      "| stddev|0.26601855904004307|\n",
      "|    min|                  0|\n",
      "|    max|                  1|\n",
      "+-------+-------------------+\n",
      "\n",
      "+-------+--------------+\n",
      "|summary|PossessionTeam|\n",
      "+-------+--------------+\n",
      "|  count|          2689|\n",
      "|   mean|          null|\n",
      "| stddev|          null|\n",
      "|    min|           ARZ|\n",
      "|    max|           TEN|\n",
      "+-------+--------------+\n",
      "\n",
      "+-------+------------------+\n",
      "|summary|         HomeScore|\n",
      "+-------+------------------+\n",
      "|  count|              2689|\n",
      "|   mean|15.115284492376349|\n",
      "| stddev|12.516213618780784|\n",
      "|    min|                 0|\n",
      "|    max|                58|\n",
      "+-------+------------------+\n",
      "\n",
      "+-------+------------------+\n",
      "|summary|      VisitorScore|\n",
      "+-------+------------------+\n",
      "|  count|              2689|\n",
      "|   mean|6.0762365191521015|\n",
      "| stddev| 6.830194133578574|\n",
      "|    min|                 0|\n",
      "|    max|                24|\n",
      "+-------+------------------+\n",
      "\n",
      "+-------+--------------------+\n",
      "|summary|     PlayDescription|\n",
      "+-------+--------------------+\n",
      "|  count|                2689|\n",
      "|   mean|                null|\n",
      "| stddev|                null|\n",
      "|    min|(10:00) L.Washing...|\n",
      "|    max|W.Batson kicks 58...|\n",
      "+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in gameDF.columns:\n",
    "    gameDF.select(col).describe().show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would say that there are more than a few issues with the columns, all of which will be remedied\n",
    "\n",
    "1. IsScoringPlay should be boolean (assuming these are for recording keeping and not one-hot encoded for analytics)\n",
    "2. The following columns should be of short type, extra storage could have impact analytics downstream:\n",
    "    * Sequence\n",
    "    * Quarter\n",
    "    * HomeScore\n",
    "    * VisitorScore\n",
    "    * SpecialTeamsPlay\n",
    "    * AbsoluteYardLine\n",
    "    * YardsToGo\n",
    "    * Down\n",
    "    * PlayID\n",
    "    \n",
    "3. It feels very unnatural to separate the Date from the clock. If you are wanting to oder the entried by when they occurred, then these need to be combined in some way. Either as a DateTime (using DateType) or as an epoch (timestamp). My personal preference, due to simplicity of an epoch, is to convert their concatenation to a TimestampType \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#datetime converter\n",
    "import datetime\n",
    "def convert_date_and_time_to_timestamp(date,time):\n",
    "    try:\n",
    "        #return ('{0} {1}'.format(date,time))\n",
    "        value = datetime.datetime.strptime('{0} {1}'.format(str(date),str(time)),'%m/%d/%Y %H:%M:%S')\n",
    "    except:\n",
    "        value = None\n",
    "    return value\n",
    "\n",
    "from pyspark.sql.types import TimestampType\n",
    "datetimeUDF = F.udf(lambda x,y: convert_date_and_time_to_timestamp(x,y),TimestampType())\n",
    "\n",
    "from pyspark.sql.types import DateType,BooleanType\n",
    "gameDF = gameDF.withColumn('GameTime',datetimeUDF(gameDF.GameDate,gameDF.UniversalTimeClock))\\\n",
    ".drop('GameDate').drop('UniversalTimeClock')\n",
    "\n",
    "# short conversions - since this converstion uses all columns (some with identity transform), it is performed after teh datetime conversion to epoch\n",
    "columns_to_convert_to_short = ['Sequence','Quarter','HomeScore','VisitorScore','SpecialTeamsPlay','AbsoluteYardLine','YardsToGo','Down','PlayID']\n",
    "short_conversion_expressions = [F.col(name).cast('short').alias(name) if name in columns_to_convert_to_short else F.col(name).alias(name) for name in gameDF.columns]\n",
    "\n",
    "gameDF = gameDF.withColumn('IsScoringPlay',gameDF.IsScoringPlay.cast(BooleanType()))\\\n",
    ".select(*short_conversion_expressions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the schema looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- GameKey: integer (nullable = true)\n",
      " |-- PlayID: short (nullable = true)\n",
      " |-- HomeClubCode: string (nullable = true)\n",
      " |-- VisitorClubCode: string (nullable = true)\n",
      " |-- ClockTime: string (nullable = true)\n",
      " |-- Down: short (nullable = true)\n",
      " |-- YardsToGo: short (nullable = true)\n",
      " |-- YardLine: string (nullable = true)\n",
      " |-- AbsoluteYardLine: short (nullable = true)\n",
      " |-- SpecialTeamsPlay: short (nullable = true)\n",
      " |-- Quarter: short (nullable = true)\n",
      " |-- Sequence: short (nullable = true)\n",
      " |-- IsScoringPlay: boolean (nullable = true)\n",
      " |-- PossessionTeam: string (nullable = true)\n",
      " |-- HomeScore: short (nullable = true)\n",
      " |-- VisitorScore: short (nullable = true)\n",
      " |-- PlayDescription: string (nullable = true)\n",
      " |-- GameTime: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gameDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the resulting DataFrame is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------------+---------------+---------+----+---------+--------+----------------+----------------+-------+--------+-------------+--------------+---------+------------+--------------------+--------------------+\n",
      "|GameKey|PlayID|HomeClubCode|VisitorClubCode|ClockTime|Down|YardsToGo|YardLine|AbsoluteYardLine|SpecialTeamsPlay|Quarter|Sequence|IsScoringPlay|PossessionTeam|HomeScore|VisitorScore|     PlayDescription|            GameTime|\n",
      "+-------+------+------------+---------------+---------+----+---------+--------+----------------+----------------+-------+--------+-------------+--------------+---------+------------+--------------------+--------------------+\n",
      "|  55774|    53|         SEA|            TEN|    15:00|   0|        0|  SEA 35|              65|               1|      1|      53|        false|           SEA|        0|           0|C.Wiggs kicks 65 ...|2012-08-11 02:05:...|\n",
      "|  55774|    71|         SEA|            TEN|    15:00|   1|       10|  TEN 20|              80|               0|      1|      71|         true|           TEN|        6|           0|(15:00) M.Hasselb...|2012-08-11 02:06:...|\n",
      "|  55774|   144|         SEA|            TEN|    14:51|   0|        0|   TEN 2|               2|               1|      1|     144|         true|           SEA|        7|           0|S.Hauschka extra ...|2012-08-11 02:10:...|\n",
      "|  55774|   160|         SEA|            TEN|    14:51|   0|        0|  SEA 35|              65|               1|      1|     160|        false|           SEA|        7|           0|C.Wiggs kicks 65 ...|2012-08-11 02:11:...|\n",
      "|  55774|   178|         SEA|            TEN|    14:51|   1|       10|  TEN 20|              80|               0|      1|     178|        false|           TEN|        7|           0|(14:51) C.Johnson...|2012-08-11 02:12:...|\n",
      "|  55774|   199|         SEA|            TEN|    14:16|   2|       13|  TEN 17|              83|               0|      1|     199|        false|           TEN|        7|           0|(14:16) C.Johnson...|2012-08-11 02:12:...|\n",
      "|  55774|   220|         SEA|            TEN|    13:31|   3|        4|  TEN 26|              74|               0|      1|     220|        false|           TEN|        7|           0|(13:31) (Shotgun)...|2012-08-11 02:13:...|\n",
      "|  55774|   244|         SEA|            TEN|    13:04|   1|       10|  TEN 36|              64|               0|      1|     244|        false|           TEN|        7|           0|(13:04) C.Johnson...|2012-08-11 02:14:...|\n",
      "|  55774|   265|         SEA|            TEN|    12:27|   2|        9|  TEN 37|              63|               0|      1|     265|        false|           TEN|        7|           0|(12:27) M.Hasselb...|2012-08-11 02:14:...|\n",
      "|  55774|   287|         SEA|            TEN|    12:22|   3|        9|  TEN 37|              63|               0|      1|     287|        false|           TEN|        7|           0|(12:22) (Shotgun)...|2012-08-11 02:15:...|\n",
      "|  55774|   316|         SEA|            TEN|    12:18|   4|        9|  TEN 37|              63|               1|      1|     316|        false|           TEN|        7|           0|(12:18) B.Kern pu...|2012-08-11 02:16:...|\n",
      "|  55774|   341|         SEA|            TEN|    12:08|   1|       10|  SEA 15|              85|               0|      1|     341|        false|           SEA|        7|           0|(12:08) M.Flynn p...|2012-08-11 02:18:...|\n",
      "|  55774|   365|         SEA|            TEN|    11:32|   2|        5|  SEA 20|              80|               0|      1|     365|        false|           SEA|        7|           0|(11:32) L.Washing...|2012-08-11 02:19:...|\n",
      "|  55774|   386|         SEA|            TEN|    10:55|   1|       10|  SEA 29|              71|               0|      1|     386|        false|           SEA|        7|           0|(10:55) L.Washing...|2012-08-11 02:20:...|\n",
      "|  55774|   407|         SEA|            TEN|    10:13|   2|        1|  SEA 38|              62|               0|      1|     407|        false|           SEA|        7|           0|(10:13) L.Washing...|2012-08-11 02:20:...|\n",
      "|  55774|   428|         SEA|            TEN|     9:32|   1|       10|  SEA 46|              54|               0|      1|     428|        false|           SEA|        7|           0|(9:32) M.Flynn pa...|2012-08-11 02:21:...|\n",
      "|  55774|   452|         SEA|            TEN|     8:46|   2|        5|  TEN 49|              49|               0|      1|     452|        false|           SEA|        7|           0|(8:46) R.Turbin r...|2012-08-11 02:22:...|\n",
      "|  55774|   473|         SEA|            TEN|     8:04|   3|        4|  TEN 48|              48|               0|      1|     473|        false|           SEA|        7|           0|(8:04) (Shotgun) ...|2012-08-11 02:22:...|\n",
      "|  55774|   506|         SEA|            TEN|     8:00|   1|       10|  TEN 44|              44|               0|      1|     506|        false|           SEA|        7|           0|(8:00) M.Flynn pa...|2012-08-11 02:23:...|\n",
      "|  55774|   530|         SEA|            TEN|     7:19|   2|        6|  TEN 40|              40|               0|      1|     530|        false|           SEA|        7|           0|(7:19) (Shotgun) ...|2012-08-11 02:24:...|\n",
      "+-------+------+------------+---------------+---------+----+---------+--------+----------------+----------------+-------+--------+-------------+--------------+---------+------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gameDF.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
